{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting import-ipynb\n",
      "  Downloading import-ipynb-0.1.3.tar.gz (4.0 kB)\n",
      "Building wheels for collected packages: import-ipynb\n",
      "  Building wheel for import-ipynb (setup.py): started\n",
      "  Building wheel for import-ipynb (setup.py): finished with status 'done'\n",
      "  Created wheel for import-ipynb: filename=import_ipynb-0.1.3-py3-none-any.whl size=2979 sha256=405bdcb4d2a2505e2c94f290f77a9012931ab22239927e84f1d7b35ed79fefd7\n",
      "  Stored in directory: c:\\users\\rames\\appdata\\local\\pip\\cache\\wheels\\06\\7e\\ad\\1cb03e935234186825cefc7e2c8f3451b4f654b5bc72232a7b\n",
      "Successfully built import-ipynb\n",
      "Installing collected packages: import-ipynb\n",
      "Successfully installed import-ipynb-0.1.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import ast\n",
    "import math\n",
    "!pip install import-ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntropyBasedItemset:\n",
    "    def __init__(self, master):\n",
    "        self.master = master\n",
    "    \n",
    "    def getSubsetNotNA(self, df, columnName):\n",
    "        data = df.copy()\n",
    "        data = data[data[columnName].notna()]\n",
    "        return data\n",
    "    \n",
    "    def CombineCourseGrade(self, data1, column1, column2):\n",
    "        data = data1.copy()\n",
    "        data['CourseGradeCombo'] = \"\"\n",
    "        data[column1] = data[column1].apply(ast.literal_eval)\n",
    "        data[column2] = data[column2].apply(ast.literal_eval)\n",
    "        for idx, row in data.iterrows():\n",
    "            courseList = row[column1]\n",
    "            gradeList = row[column2]\n",
    "            #print(type(courseList))\n",
    "            combo = dict(zip(courseList, gradeList))\n",
    "            #print(combo)\n",
    "            #data.set_value(idx, 'CourseGradeCombo', combo)\n",
    "            data.at[idx,'CourseGradeCombo']=combo\n",
    "        return(data)\n",
    "    \n",
    "    def SplitCourseToIndividualRows(self, data, columnName):\n",
    "        df = pd.DataFrame([[i, k, v] for i, d in data[[columnName,'CourseGradeCombo']].values for k, v in d.items()],\n",
    "                  columns=[columnName,'CourseIndivName','CourseIndivGrade'])\n",
    "        return df\n",
    "    \n",
    "    def preprocessCourseNameGradeIndiv(self, data):\n",
    "        df = data.copy()\n",
    "        df.CourseIndivGrade = df.CourseIndivGrade.str.replace(\"\\\"\",'')\n",
    "        df.CourseIndivName = df.CourseIndivName.str.strip().str.lower().str.replace(\"-i\",\" - i\")\n",
    "        df.CourseIndivName = df.CourseIndivName.str.replace(\"web technologies 1\", \"web technologies - i\")\n",
    "        df.CourseIndivName = df.CourseIndivName.str.replace(\"technology\", \"technologies\")\n",
    "        df.CourseIndivName = df.CourseIndivName.str.replace(\"web technologies- i\", \"web technologies - i\")\n",
    "        df.CourseIndivName = df.CourseIndivName.str.replace(\"web technologies ii\", \"web technologies - ii\")\n",
    "        return df\n",
    "    \n",
    "    def setMapGradeToNumber(self, mapDict):\n",
    "        mapDict = {\"S\": \"7\", \"A\":\"6\", \"B\":\"5\" ,\"C\":\"4\", \"D\":\"3\", \"E\":\"2\", \"F\":\"1\", \"N\":\"0\"}\n",
    "        self.gradeMap = mapDict\n",
    "    \n",
    "    def mapColumnGradeToNumber(self, df, gradeColumnName):\n",
    "        data = df.copy()\n",
    "        #print(type(data[gradeColumnName]))\n",
    "        data[gradeColumnName] = data[gradeColumnName].str.replace(\"\\\"\",'')\n",
    "        data[gradeColumnName] = data[gradeColumnName].str.replace(\"AP\",\"N\")\n",
    "        for grade, val in self.gradeMap.items():\n",
    "            #print(grade, val)\n",
    "            data[gradeColumnName] = data[gradeColumnName].str.replace(grade, val)\n",
    "        return data\n",
    "    \n",
    "    def createSubjectSubset(self, df, courseName):\n",
    "        df1 = df.copy()\n",
    "        df1 = df1[df1.CourseIndivName == courseName]\n",
    "        return df1\n",
    "        \n",
    "    def masterDataBinSplitonTier(self, data, tierVal):\n",
    "        dataset = data.copy()\n",
    "        #create a new column for splitting as binary values, if it is the given tier, then will be labelled 1 , else 0\n",
    "        dataset['TierBinSplitVal'] = (dataset.TierLevel == float(tierVal)).map({True:1 , False: 0})\n",
    "        return dataset\n",
    "    \n",
    "    def masterDataBinSplitonColumn(self, data, columnName, columnVal):\n",
    "        dataset = data.copy()\n",
    "        #create a new column for splitting as binary values, if it is the given tier, then will be labelled 1 , else 0\n",
    "        dataset[columnName+'BinSplitVal'] = (dataset[columnName] == columnVal).map({True:1 , False: 0})\n",
    "        return dataset\n",
    "    \n",
    "    def masterDataBinSplitonGrade(self, data, grade):\n",
    "        dataset = data.copy()\n",
    "        dataset[\"CourseIndivGrade\"] = pd.to_numeric(dataset['CourseIndivGrade'])\n",
    "        #create a new col for 10th interval, if it is greater than or equal to given 10th percentage then we label as 1, else 0\n",
    "        dataset['CourseGradeBinSplitVal'] = (dataset['CourseIndivGrade'] >= grade).map({True:1 , False: 0})\n",
    "        return dataset\n",
    "    \n",
    "    def masterDataBinSpliton10th( self, data, perc10):\n",
    "        dataset = data.copy()\n",
    "        #create a new col for 10th interval, if it is greater than or equal to given 10th percentage then we label as 1, else 0\n",
    "        dataset['10PercBinSplitVal'] = (dataset['10thPercentage'] >= float(perc10)).map({True:1 , False: 0})\n",
    "        return dataset\n",
    "    \n",
    "    def masterDataBinSpliton12th( self, data, perc12):\n",
    "        dataset = data.copy()\n",
    "        #create a new col for 10th interval, if it is greater than or equal to given 10th percentage then we label as 1, else 0\n",
    "        dataset['12PercBinSplitVal'] = (dataset['12thPercentage'] >= float(perc12)).map({True:1 , False: 0})\n",
    "        return dataset\n",
    "    \n",
    "    def calc_entropy(self, column):\n",
    "        \"\"\"\n",
    "        Calculate entropy given a pandas series, list, or numpy array.\n",
    "        \"\"\"\n",
    "        # Compute the counts of each unique value in the column\n",
    "        counts = np.bincount(column)\n",
    "        # Divide by the total column length to get a probability\n",
    "        probabilities = counts / len(column)\n",
    "\n",
    "        # Initialize the entropy to 0\n",
    "        entropy = 0\n",
    "        # Loop through the probabilities, and add each one to the total entropy\n",
    "        for prob in probabilities:\n",
    "            if prob > 0:\n",
    "                # use log from math and set base to 2\n",
    "                entropy += prob * math.log(prob, 2)\n",
    "\n",
    "        return -entropy\n",
    "    \n",
    "    def calc_information_gain(self, data, split_name, target_name):\n",
    "        \"\"\"\n",
    "        Calculate information gain given a data set, column to split on, and target\n",
    "        \"\"\"\n",
    "        # Calculate the original entropy\n",
    "        original_entropy = self.calc_entropy(data[target_name])\n",
    "\n",
    "        #Find the unique values in the column\n",
    "        values = data[split_name].unique()\n",
    "        #print(values)      \n",
    "            \n",
    "        # Make two subsets of the data, based on the unique values\n",
    "        left_split = data[data[split_name] == values[0]]\n",
    "        right_split = data[data[split_name] == values[1]]\n",
    "\n",
    "        # Loop through the splits and calculate the subset entropies\n",
    "        to_subtract = 0\n",
    "        for subset in [left_split, right_split]:\n",
    "            prob = (subset.shape[0] / data.shape[0]) \n",
    "            to_subtract += prob * self.calc_entropy(subset[target_name])\n",
    "\n",
    "        # Return information gain\n",
    "        return original_entropy - to_subtract\n",
    "\n",
    "    def getEntropy10th(self, df, columnName, columnVal):\n",
    "        #Now repeat the above process for CGPA by trying for each value differing by 0.1,\n",
    "        #parallely see which threshold CGPA gives the max info gain(min entropy) and update the same\n",
    "        #store the information gains for each CGPA threshold in infGainMap\n",
    "        data = df.copy()\n",
    "        data1 = self.masterDataBinSplitonColumn(data, columnName, columnVal)\n",
    "        i = 60.0\n",
    "        infGainMap = {}\n",
    "        maxInfGain = [-1,-1]\n",
    "        while(i<=100):\n",
    "            #print(i)\n",
    "            i = round(i,1)\n",
    "            tempData = self.masterDataBinSpliton10th(data1, i)\n",
    "            if(len(tempData['10PercBinSplitVal'].unique())<2):\n",
    "                tempVal = i\n",
    "                infGain = -100000\n",
    "            else:\n",
    "                infGain = self.calc_information_gain(tempData, '10PercBinSplitVal', columnName+'BinSplitVal')\n",
    "            infGainMap[i] = infGain\n",
    "            if(maxInfGain[1]< infGain):\n",
    "                maxInfGain[0] = i\n",
    "                maxInfGain[1] = infGain\n",
    "            #print(infGain)\n",
    "            #print(\"\\n\")\n",
    "            i= i +1\n",
    "        maxInf = maxInfGain[0]\n",
    "        if(maxInfGain[0]==-1 and tempVal!=-1):\n",
    "            maxInf = tempVal\n",
    "        #map_grade = {\"S\": 7, \"A\":6, \"B\":5 ,\"C\":4, \"D\":3, \"E\":2, \"F\":1, \"NA\":-1}\n",
    "        #listOfKeys = [key  for (key, value) in map_grade.items() if value == maxInf ]\n",
    "        self.Optimal10thMarks = maxInf\n",
    "        return maxInf\n",
    "    \n",
    "    def getEntropy12th(self, df, columnName, columnVal):\n",
    "        #Now repeat the above process for CGPA by trying for each value differing by 0.1,\n",
    "        #parallely see which threshold CGPA gives the max info gain(min entropy) and update the same\n",
    "        #store the information gains for each CGPA threshold in infGainMap\n",
    "        data = df.copy()\n",
    "        data1 = self.masterDataBinSplitonColumn(data, columnName, columnVal)\n",
    "        i = 60.0\n",
    "        infGainMap = {}\n",
    "        maxInfGain = [-1,-1]\n",
    "        while(i<=100):\n",
    "            #print(i)\n",
    "            i = round(i,1)\n",
    "            tempData = self.masterDataBinSpliton12th(data1, i)\n",
    "            if(len(tempData['12PercBinSplitVal'].unique())<2):\n",
    "                tempVal = i\n",
    "                infGain = -100000\n",
    "            else:\n",
    "                infGain = self.calc_information_gain(tempData, '12PercBinSplitVal', columnName+'BinSplitVal')\n",
    "            infGainMap[i] = infGain\n",
    "            if(maxInfGain[1]< infGain):\n",
    "                maxInfGain[0] = i\n",
    "                maxInfGain[1] = infGain\n",
    "            #print(infGain)\n",
    "            #print(\"\\n\")\n",
    "            i= i +1\n",
    "            \n",
    "        maxInf = maxInfGain[0]\n",
    "        if(maxInfGain[0]==-1 and tempVal!=-1):\n",
    "            maxInf = tempVal\n",
    "        #map_grade = {\"S\": 7, \"A\":6, \"B\":5 ,\"C\":4, \"D\":3, \"E\":2, \"F\":1, \"NA\":-1}\n",
    "        #listOfKeys = [key  for (key, value) in map_grade.items() if value == maxInf ]\n",
    "        self.Optimal12thMarks = maxInf\n",
    "        return maxInf\n",
    "\n",
    "    def getEntropyGrade(self, df, courseName, columnName, columnVal):\n",
    "        subSubset = self.createSubjectSubset(df, courseName)\n",
    "        #split dataset on tier, n this case trying Tier1\n",
    "        subSetSub = self.masterDataBinSplitonColumn(subSubset, columnName, columnVal )\n",
    "        #parallely see which threshold Grade gives the max info gain(min entropy) and update the same\n",
    "        #store the information gains for each Grade threshold in infGainMap\n",
    "        tempVal = -1\n",
    "        i = 2\n",
    "        infGainMap = {}\n",
    "        maxInfGain = [-1,-1]\n",
    "        while(i<=7):\n",
    "            #print(i)\n",
    "            i = round(i,1)\n",
    "            tempData = self.masterDataBinSplitonGrade(subSetSub, i)\n",
    "            #print(tempData)\n",
    "            if(len(tempData['CourseGradeBinSplitVal'].unique())<2):\n",
    "                tempVal = i\n",
    "                infGain = -100000\n",
    "            else:\n",
    "                infGain = self.calc_information_gain(tempData, 'CourseGradeBinSplitVal', columnName+'BinSplitVal')\n",
    "            infGainMap[i] = infGain\n",
    "            if(maxInfGain[1]< infGain):\n",
    "                maxInfGain[0] = i\n",
    "                maxInfGain[1] = infGain\n",
    "            #print(infGain)\n",
    "            #print(\"\\n\")\n",
    "            i= i +1\n",
    "\n",
    "        #print(\"\\n\\nMaximum information gain is found for : \" + str(maxInfGain[0]) + \" with value \" + str(maxInfGain[1]))\n",
    "        maxInf = maxInfGain[0]\n",
    "        if(maxInfGain[0]==-1 and tempVal!=-1):\n",
    "            maxInf = tempVal\n",
    "        #map_grade = {\"S\": 7, \"A\":6, \"B\":5 ,\"C\":4, \"D\":3, \"E\":2, \"F\":1, \"NA\":-1}\n",
    "        #listOfKeys = [key  for (key, value) in map_grade.items() if value == maxInf ]\n",
    "        return maxInf\n",
    "    \n",
    "    def getOptimalGradeForAllCourses(self, data, columnName, columnVal, gradeColumnName, courseColumnName):\n",
    "        df = data.copy()\n",
    "        df = self.getSubsetNotNA(df, columnName)\n",
    "        self.setMapGradeToNumber({})\n",
    "        df1 = self.mapColumnGradeToNumber(df, gradeColumnName)\n",
    "        df2 = self.CombineCourseGrade(df1, courseColumnName, gradeColumnName)\n",
    "        #print(df2['CourseGradeCombo'])\n",
    "        df3 = self.SplitCourseToIndividualRows(df2, columnName)\n",
    "        df4 = self.preprocessCourseNameGradeIndiv(df3)\n",
    "        #print(type(df4.CourseIndivGrade))\n",
    "        listOfCourses = df4.CourseIndivName.unique()\n",
    "        courseOptimalGrade = {}\n",
    "        for course in listOfCourses:\n",
    "            #print(course)\n",
    "            grade = self.getEntropyGrade(df4, course, columnName, columnVal)\n",
    "            courseOptimalGrade[course] = grade\n",
    "        self.courseOptimalGrade = courseOptimalGrade\n",
    "        df5 = self.addCourseGradeBasedItemset(df2, courseOptimalGrade, courseColumnName)\n",
    "        return df5\n",
    "    \n",
    "    def addCourseGradeBasedItemset(self, df, courseOptimalGrade, courseColumnName):\n",
    "        data = df.copy()\n",
    "        #courseoptimalGrade = self.courseOptimalGrade\n",
    "        #print(courseOptimalGrade)\n",
    "        map_grade = {7: \"S\", 6:\"A\", 5:\"B\" ,4:\"C\", 3:\"D\", 2:\"E\", 1:\"F\", 0:\"NA\",-1:\"NA\"}\n",
    "        #print(data.columns)\n",
    "        data['ValidCourses']=\"\"\n",
    "        for idx, row in data.iterrows():\n",
    "            validCourses = []\n",
    "            for key in row['CourseGradeCombo']:\n",
    "                row['CourseGradeCombo'][key] = int( row['CourseGradeCombo'][key])\n",
    "                #print(keyPreProc)\n",
    "                keyPreProc =key.strip().lower().replace(\"-i\",\" - i\").replace(\"web technologies 1\", \"web technologies - i\").replace(\"technology\", \"technologies\").replace(\"web technologies- i\", \"web technologies - i\").replace(\"web technologies ii\", \"web technologies - ii\")\n",
    "                #print(keyPreProc)\n",
    "                if(keyPreProc in courseOptimalGrade):\n",
    "                    if(row['CourseGradeCombo'][key]>= courseOptimalGrade[keyPreProc]):\n",
    "                        validCourses.append(courseColumnName+\"_\"+keyPreProc+\"::\"+map_grade[courseOptimalGrade[keyPreProc]]+\" and higher\")\n",
    "                else:\n",
    "                    print(\"key not oresent\", key)\n",
    "            #print(validCourses)\n",
    "            data.at[idx,'ValidCourses'] = validCourses\n",
    "        self.validCoursesData = data[['USN','ValidCourses']]\n",
    "        return data[['USN','ValidCourses']]\n",
    "    \n",
    "    def getOptimal10thMarks(self):\n",
    "        return self.Optimal10thMarks\n",
    "    \n",
    "    def getOptimal10thMarks(self):\n",
    "        return self.Optimal12thMarks\n",
    "    \n",
    "    def getValidCoursesItemset(self):\n",
    "        return self.validCoursesData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'combinedMasterLatest.csv'\n",
    "master = pd.read_csv (path) \n",
    "obj = EntropyBasedItemset(master)\n",
    "datatemp = obj.getOptimalGradeForAllCourses(master, 'TierLevel', '1', 'CourseGrade', 'CourseName')\n",
    "Entropy10thVal = obj.getEntropy10th(master, 'TierLevel', '1')\n",
    "Entropy12thVal = obj.getEntropy12th(master, 'TierLevel', '1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'USN', '10thPercentage', '12thPercentage', 'AwardsNLP',\n",
       "       'Branch', 'CGPA', 'CTC', 'CoCurricularActivities', 'CompanyNameNLP',\n",
       "       'CoreCourseGrade', 'CoreCourseName', 'CourseGrade', 'CourseName',\n",
       "       'ElectiveCourseGrade', 'ElectiveCourseName', 'EmploymentType',\n",
       "       'ExternalCertificatesDomain', 'ExternalCertificatesKey',\n",
       "       'GeneralSkills', 'GitHubLink', 'InternshipCompany',\n",
       "       'InternshipProjectDomain', 'LanguagesNLP', 'LinkedInLink',\n",
       "       'MinorAttended', 'Name', 'NoofInternships', 'NoofProjects',\n",
       "       'NumberOfOffers', 'OtherDetails', 'ProgLanguages',\n",
       "       'ProjectDetailDomain', 'PublicationNLP', 'ResearchDomain',\n",
       "       'ScholarshipsNLP', 'Stipend(K)', 'TierLevel', 'VolunteeringWork',\n",
       "       'WorkshopsDomain', 'WorkshopsOrg', 'SoftwareTools', 'ProgLanguagesNLP'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
